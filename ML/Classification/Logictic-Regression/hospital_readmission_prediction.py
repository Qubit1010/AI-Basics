"""
LOGISTIC REGRESSION CLASSIFICATION - HOSPITAL READMISSION PREDICTION
=====================================================================
Predicting whether a patient will be readmitted within 30 days of discharge

Perfect Scenario for Logistic Regression:
- Binary classification (Readmitted Yes/No within 30 days)
- Need probability output (risk score for each patient)
- Interpretable coefficients (doctors need to understand WHY)
- Clinical features have mostly linear log-odds relationships
- Regulatory compliance requires explainability (not black box)
- Small-to-medium dataset with structured clinical data

Dataset: Hospital Patient Discharge Records (Generated)
Features:
- Age (years)
- Length of Stay (days)
- Number of Diagnoses
- Number of Procedures
- Number of Medications
- Number of Lab Tests
- Number of Previous Admissions (past year)
- HbA1c Result (blood sugar control)
- Discharge Type (Home / Skilled Nursing / AMA)
- Primary Diagnosis Category (Circulatory, Respiratory, Diabetes, etc.)
- Insurance Type (Medicare, Medicaid, Private, Self-Pay)
- Comorbidity Score (0-10, Charlson index)
- ER Admission (Yes/No)
- Days Since Last Admission

Target: Readmitted_30days (1 = Readmitted, 0 = Not Readmitted)

Why Logistic Regression for Healthcare?
- Outputs probabilities â†’ clinicians assign risk tiers
- Coefficients are interpretable â†’ "each extra medication adds X% risk"
- FDA/regulatory friendly â†’ explainable AI requirements
- Works well when log-odds are approximately linear
- Feature weights map to real clinical insights

Approach:
1. Generate realistic patient discharge data
2. Exploratory Data Analysis
3. Data Preprocessing (encoding, scaling)
4. Build Logistic Regression models
5. Evaluate with healthcare-relevant metrics
6. Decision threshold optimization
7. Coefficient interpretation
8. Visualizations
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold
from sklearn.metrics import (classification_report, confusion_matrix,
                             roc_auc_score, roc_curve, precision_recall_curve,
                             accuracy_score, f1_score, average_precision_score)
from sklearn.preprocessing import StandardScaler, LabelEncoder
import warnings

warnings.filterwarnings('ignore')

import matplotlib

matplotlib.use('Agg')

sns.set_style('whitegrid')
plt.rcParams['figure.figsize'] = (12, 6)

print("=" * 80)
print("LOGISTIC REGRESSION CLASSIFICATION - HOSPITAL READMISSION PREDICTION")
print("=" * 80)

# ============================================================================
# STEP 1: GENERATE REALISTIC PATIENT DISCHARGE DATA
# ============================================================================
print("\n" + "=" * 80)
print("STEP 1: GENERATE REALISTIC PATIENT DISCHARGE DATA")
print("=" * 80)

np.random.seed(42)
n_patients = 2000

print(f"\nGenerating {n_patients} patient discharge records...")

# --- Numerical Features ---
age = np.random.randint(18, 95, n_patients)
length_of_stay = np.random.exponential(scale=5, size=n_patients).clip(1, 30).astype(int)
num_diagnoses = np.random.randint(1, 15, n_patients)
num_procedures = np.random.randint(0, 10, n_patients)
num_medications = np.random.randint(1, 25, n_patients)
num_lab_tests = np.random.randint(1, 30, n_patients)
num_prev_admissions = np.random.poisson(lam=1.5, size=n_patients).clip(0, 8)
comorbidity_score = np.random.randint(0, 11, n_patients)
days_since_last_adm = np.random.exponential(scale=90, size=n_patients).clip(0, 365).astype(int)

# HbA1c (blood sugar) - relevant for diabetic patients
hba1c_options = ['Normal', 'Abnormal', 'Not Tested']
hba1c = np.random.choice(hba1c_options, n_patients, p=[0.35, 0.35, 0.30])

# --- Categorical Features ---
discharge_type = np.random.choice(
    ['Home', 'Skilled Nursing Facility', 'Against Medical Advice'],
    n_patients, p=[0.65, 0.25, 0.10]
)

diagnosis_category = np.random.choice(
    ['Circulatory', 'Respiratory', 'Diabetes', 'Musculoskeletal', 'Other'],
    n_patients, p=[0.30, 0.20, 0.20, 0.15, 0.15]
)

insurance_type = np.random.choice(
    ['Medicare', 'Medicaid', 'Private', 'Self-Pay'],
    n_patients, p=[0.45, 0.25, 0.20, 0.10]
)

er_admission = np.random.choice([1, 0], n_patients, p=[0.55, 0.45])

# --- Generate Readmission Label (realistic clinical logic) ---
print("\nGenerating readmission labels based on realistic clinical risk factors:")
print("  â€¢ High previous admissions â†’ higher risk")
print("  â€¢ AMA discharge â†’ much higher risk")
print("  â€¢ High comorbidity â†’ higher risk")
print("  â€¢ Short days since last admission â†’ higher risk")
print("  â€¢ Abnormal HbA1c â†’ higher risk for diabetics")
print("  â€¢ Self-Pay insurance â†’ higher risk (care access issues)")
print("  â€¢ More medications â†’ higher risk (complex cases)")

log_odds = (
        -2.5  # Baseline intercept
        + 0.03 * age  # Older â†’ higher risk
        + 0.05 * num_prev_admissions  # More admissions â†’ higher
        + 0.08 * comorbidity_score  # Sicker patients
        + 0.04 * num_medications  # Complex medication regime
        - 0.03 * days_since_last_adm / 30  # Recent discharge â†’ higher
        + 0.06 * er_admission  # ER â†’ higher risk
        + 0.4 * (discharge_type == 'Against Medical Advice')  # AMA discharge
        - 0.2 * (discharge_type == 'Skilled Nursing Facility')  # Better post-care
        + 0.3 * (hba1c == 'Abnormal')  # Poor glucose control
        + 0.25 * (insurance_type == 'Self-Pay')  # Access barriers
        + 0.15 * (insurance_type == 'Medicaid')  # Access barriers
        + 0.2 * (diagnosis_category == 'Circulatory')  # Complex disease
        + 0.15 * (diagnosis_category == 'Diabetes')  # Chronic management
        + np.random.normal(0, 0.5, n_patients)  # Random variation
)

prob_readmission = 1 / (1 + np.exp(-log_odds))
readmitted = (np.random.uniform(0, 1, n_patients) < prob_readmission).astype(int)

# --- Build DataFrame ---
df = pd.DataFrame({
    'Age': age,
    'LengthOfStay': length_of_stay,
    'NumDiagnoses': num_diagnoses,
    'NumProcedures': num_procedures,
    'NumMedications': num_medications,
    'NumLabTests': num_lab_tests,
    'NumPrevAdmissions': num_prev_admissions,
    'ComorbidityScore': comorbidity_score,
    'DaysSinceLastAdm': days_since_last_adm,
    'HbA1c': hba1c,
    'DischargeType': discharge_type,
    'DiagnosisCategory': diagnosis_category,
    'InsuranceType': insurance_type,
    'ERAdmission': er_admission,
    'Readmitted_30days': readmitted
})

print(f"\nâœ“ Dataset generated successfully!")
print(f"  Shape: {df.shape}")
print(f"  Features: {df.shape[1] - 1}")
print(f"  Target: Readmitted_30days")

print("\n--- First 10 Patients ---")
print(df.head(10).to_string(index=False))

# ============================================================================
# STEP 2: EXPLORATORY DATA ANALYSIS
# ============================================================================
print("\n" + "=" * 80)
print("STEP 2: EXPLORATORY DATA ANALYSIS")
print("=" * 80)

readmit_rate = df['Readmitted_30days'].mean()
readmit_count = df['Readmitted_30days'].sum()
not_readmit_count = len(df) - readmit_count

print(f"\n--- Target Variable Distribution ---")
print(f"  Readmitted (30 days):     {readmit_count:,} patients ({readmit_rate * 100:.1f}%)")
print(f"  Not Readmitted:           {not_readmit_count:,} patients ({(1 - readmit_rate) * 100:.1f}%)")
print(f"  Class Imbalance Ratio:    1 : {not_readmit_count / readmit_count:.2f}")

print(f"\n--- Readmission by Discharge Type ---")
print(df.groupby('DischargeType')['Readmitted_30days'].agg(['mean', 'count'])
      .rename(columns={'mean': 'Readmit Rate', 'count': 'Total'})
      .round(3))

print(f"\n--- Readmission by Diagnosis Category ---")
print(df.groupby('DiagnosisCategory')['Readmitted_30days'].agg(['mean', 'count'])
      .rename(columns={'mean': 'Readmit Rate', 'count': 'Total'})
      .round(3))

print(f"\n--- Readmission by Insurance Type ---")
print(df.groupby('InsuranceType')['Readmitted_30days'].agg(['mean', 'count'])
      .rename(columns={'mean': 'Readmit Rate', 'count': 'Total'})
      .round(3))

print(f"\n--- Numerical Feature Statistics ---")
num_cols = ['Age', 'LengthOfStay', 'NumDiagnoses', 'NumMedications',
            'NumPrevAdmissions', 'ComorbidityScore', 'DaysSinceLastAdm']
print(df[num_cols].describe().round(2))

print(f"\n--- Mean Feature Values by Readmission Status ---")
print(df.groupby('Readmitted_30days')[num_cols].mean().round(2))

# ============================================================================
# STEP 3: DATA PREPROCESSING
# ============================================================================
print("\n" + "=" * 80)
print("STEP 3: DATA PREPROCESSING")
print("=" * 80)

print("\nPreprocessing steps:")
print("  1. Encode categorical variables (Label Encoding / One-Hot)")
print("  2. Scale numerical features (StandardScaler)")
print("  3. Why scaling matters for Logistic Regression:")
print("     â€¢ Uses gradient descent optimization")
print("     â€¢ Features on same scale â†’ faster convergence")
print("     â€¢ Prevents large-magnitude features from dominating")

df_processed = df.copy()

# Label encode binary/ordinal
le_hba1c = LabelEncoder()
le_discharge = LabelEncoder()
le_er = LabelEncoder()

df_processed['HbA1c_encoded'] = le_hba1c.fit_transform(df['HbA1c'])
df_processed['DischargeType_encoded'] = le_discharge.fit_transform(df['DischargeType'])

# One-Hot encode nominal categories
df_processed = pd.get_dummies(df_processed,
                              columns=['DiagnosisCategory', 'InsuranceType'],
                              drop_first=True)

# Drop original categorical columns
df_processed.drop(columns=['HbA1c', 'DischargeType'], inplace=True)

print(f"\n  Original features: {df.shape[1] - 1}")
print(f"  After encoding:    {df_processed.shape[1] - 1}")

# Feature & Target split
target_col = 'Readmitted_30days'
feature_cols = [c for c in df_processed.columns if c != target_col]

X = df_processed[feature_cols]
y = df_processed[target_col]

print(f"\n  Feature matrix shape: {X.shape}")
print(f"  Target vector shape:  {y.shape}")
print(f"\n  Features used: {feature_cols}")

# Save dataset
df.to_csv('hospital_readmission_data.csv', index=False)
print(f"\nâœ“ Raw dataset saved to: hospital_readmission_data.csv")

# ============================================================================
# STEP 4: TRAIN-TEST SPLIT
# ============================================================================
print("\n" + "=" * 80)
print("STEP 4: TRAIN-TEST SPLIT (STRATIFIED)")
print("=" * 80)

print("\nUsing Stratified Split â€” preserves class ratio in both sets")
print("  Critical for imbalanced medical datasets!")

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

print(f"\nSplit (80/20 stratified):")
print(f"  Training:  {X_train.shape[0]} patients  | Readmit rate: {y_train.mean() * 100:.1f}%")
print(f"  Test:      {X_test.shape[0]} patients  | Readmit rate: {y_test.mean() * 100:.1f}%")

# Scale numerical features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

print(f"\n  StandardScaler fitted on training data only")
print(f"  Prevents data leakage from test set into scaling")

# ============================================================================
# STEP 5: LOGISTIC REGRESSION - EXPLANATION
# ============================================================================
print("\n" + "=" * 80)
print("STEP 5: LOGISTIC REGRESSION - HOW IT WORKS")
print("=" * 80)

print("""
  Logistic Regression is a LINEAR classifier that outputs PROBABILITIES

  MATH INTUITION:
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  1. Linear combination of features:
     z = Î²â‚€ + Î²â‚Â·Age + Î²â‚‚Â·NumMeds + Î²â‚ƒÂ·ComorbScore + ...

  2. Sigmoid (Logistic) function squashes z â†’ [0, 1]:
     P(Readmitted=1) = 1 / (1 + e^(-z))

  3. Decision boundary:
     If P > 0.5 â†’ Predict Readmitted
     If P â‰¤ 0.5 â†’ Predict Not Readmitted

  4. Training (Maximum Likelihood Estimation):
     Finds Î² values that maximize the probability of
     observing the actual labels in training data

  WHY PROBABILITY OUTPUT MATTERS IN HEALTHCARE:
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  â€¢ P > 0.7 â†’ HIGH RISK: Immediate intervention
  â€¢ P 0.4â€“0.7 â†’ MEDIUM RISK: Follow-up call
  â€¢ P < 0.4 â†’ LOW RISK: Standard discharge

  REGULARIZATION (L2 / Ridge):
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  â€¢ Penalizes large coefficients â†’ prevents overfitting
  â€¢ Parameter C = 1/Î»  (lower C = stronger regularization)
""")

# ============================================================================
# STEP 6: BUILD LOGISTIC REGRESSION MODELS
# ============================================================================
print("\n" + "=" * 80)
print("STEP 6: BUILD AND COMPARE LOGISTIC REGRESSION MODELS")
print("=" * 80)

models = {
    'No Regularization': LogisticRegression(C=1e6, penalty='l2', max_iter=1000, random_state=42),
    'L2 (C=1.0)': LogisticRegression(C=1.0, penalty='l2', max_iter=1000, random_state=42),
    'L2 (C=0.1)': LogisticRegression(C=0.1, penalty='l2', max_iter=1000, random_state=42),
    'L2 (C=0.01)': LogisticRegression(C=0.01, penalty='l2', max_iter=1000, random_state=42),
}

results = {}

for name, model in models.items():
    model.fit(X_train_scaled, y_train)
    y_pred = model.predict(X_test_scaled)
    y_prob = model.predict_proba(X_test_scaled)[:, 1]

    acc = accuracy_score(y_test, y_pred)
    auc = roc_auc_score(y_test, y_prob)
    f1 = f1_score(y_test, y_pred)
    ap = average_precision_score(y_test, y_prob)

    results[name] = {
        'model': model,
        'y_pred': y_pred,
        'y_prob': y_prob,
        'Accuracy': acc,
        'ROC-AUC': auc,
        'F1-Score': f1,
        'Avg Precision': ap,
    }

    print(f"\n--- {name} ---")
    print(f"  Accuracy:        {acc:.4f}")
    print(f"  ROC-AUC:         {auc:.4f}")
    print(f"  F1-Score:        {f1:.4f}")
    print(f"  Avg Precision:   {ap:.4f}")

# Select best model (highest ROC-AUC)
best_name = max(results, key=lambda k: results[k]['ROC-AUC'])
best_model = results[best_name]['model']
y_pred = results[best_name]['y_pred']
y_prob = results[best_name]['y_prob']

print(f"\nðŸ† Best Model: {best_name} (ROC-AUC = {results[best_name]['ROC-AUC']:.4f})")

# ============================================================================
# STEP 7: DETAILED EVALUATION
# ============================================================================
print("\n" + "=" * 80)
print("STEP 7: DETAILED MODEL EVALUATION")
print("=" * 80)

print("\nExplanation of Healthcare Metrics:")
print("  Accuracy   : Overall correct predictions (misleading with imbalanced classes)")
print("  ROC-AUC    : Area under ROC curve â€” ability to discriminate (1.0 = perfect)")
print("  Sensitivity: % of actual readmissions caught (True Positive Rate)")
print("  Specificity: % of non-readmissions correctly identified")
print("  Precision  : Of predicted readmissions, % that actually readmitted")
print("  F1-Score   : Harmonic mean of precision & recall")
print("  In Healthcare: HIGH RECALL preferred â€” missing a readmission is costly!")

print(f"\n--- Classification Report ---")
print(classification_report(y_test, y_pred, target_names=['Not Readmitted', 'Readmitted']))

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
tn, fp, fn, tp = cm.ravel()

print(f"\n--- Confusion Matrix ---")
print(f"  True Negatives  (Correct: Not Readmitted): {tn}")
print(f"  False Positives (Wrong: Predicted Readmit, wasn't): {fp}")
print(f"  False Negatives (MISSED: Actually Readmitted, predicted not): {fn}  â† CRITICAL ERRORS")
print(f"  True Positives  (Correct: Caught Readmission): {tp}")

sensitivity = tp / (tp + fn)
specificity = tn / (tn + fp)
ppv = tp / (tp + fp)
npv = tn / (tn + fn)

print(f"\n--- Clinical Performance Metrics ---")
print(f"  Sensitivity (Recall):  {sensitivity:.4f}  â€” {sensitivity * 100:.1f}% of readmissions caught")
print(f"  Specificity:           {specificity:.4f}  â€” {specificity * 100:.1f}% of non-readmits correct")
print(f"  Positive Pred Value:   {ppv:.4f}  â€” When we flag a patient, {ppv * 100:.1f}% truly readmit")
print(f"  Negative Pred Value:   {npv:.4f}  â€” When we clear a patient, {npv * 100:.1f}% truly OK")
print(f"  ROC-AUC:               {results[best_name]['ROC-AUC']:.4f}")

# Cross-validation
print(f"\n--- 5-Fold Stratified Cross-Validation ---")
skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
cv_auc = cross_val_score(best_model,
                         scaler.transform(X), y,
                         cv=skf, scoring='roc_auc')
cv_f1 = cross_val_score(best_model,
                        scaler.transform(X), y,
                        cv=skf, scoring='f1')

print(f"  ROC-AUC: {cv_auc.mean():.4f} Â± {cv_auc.std():.4f}   (folds: {cv_auc.round(4)})")
print(f"  F1-Score: {cv_f1.mean():.4f} Â± {cv_f1.std():.4f}  (folds: {cv_f1.round(4)})")

# ============================================================================
# STEP 8: DECISION THRESHOLD OPTIMIZATION
# ============================================================================
print("\n" + "=" * 80)
print("STEP 8: DECISION THRESHOLD OPTIMIZATION")
print("=" * 80)

print("""
  Default threshold = 0.5
  In healthcare, we often LOWER the threshold to catch more readmissions
  Trade-off: Higher Recall â†” Lower Precision

  Hospital Decision:
  â€¢ Lower threshold â†’ flag more patients â†’ higher intervention cost
  â€¢ Higher threshold â†’ miss more readmissions â†’ CMS penalties
  â€¢ Find threshold that maximizes F1 or Sensitivity
""")

thresholds = np.arange(0.1, 0.9, 0.05)
threshold_results = []

for thresh in thresholds:
    y_pred_t = (y_prob >= thresh).astype(int)
    acc_t = accuracy_score(y_test, y_pred_t)
    f1_t = f1_score(y_test, y_pred_t, zero_division=0)

    if y_pred_t.sum() > 0:
        prec_t = tp / (tp + fp) if (tp + fp) > 0 else 0
        cm_t = confusion_matrix(y_test, y_pred_t)
        tn_t, fp_t, fn_t, tp_t = cm_t.ravel()
        rec_t = tp_t / (tp_t + fn_t) if (tp_t + fn_t) > 0 else 0
        prec_t = tp_t / (tp_t + fp_t) if (tp_t + fp_t) > 0 else 0
    else:
        rec_t, prec_t = 0, 0

    threshold_results.append({
        'Threshold': round(thresh, 2),
        'Accuracy': round(acc_t, 4),
        'Recall': round(rec_t, 4),
        'Precision': round(prec_t, 4),
        'F1': round(f1_t, 4)
    })

thresh_df = pd.DataFrame(threshold_results)
print(thresh_df.to_string(index=False))

best_thresh = thresh_df.loc[thresh_df['F1'].idxmax(), 'Threshold']
print(f"\nðŸŽ¯ Optimal Threshold (max F1): {best_thresh}")

y_pred_optimal = (y_prob >= best_thresh).astype(int)
print(f"\n--- Performance at Threshold {best_thresh} ---")
print(classification_report(y_test, y_pred_optimal,
                            target_names=['Not Readmitted', 'Readmitted']))

# ============================================================================
# STEP 9: COEFFICIENT INTERPRETATION
# ============================================================================
print("\n" + "=" * 80)
print("STEP 9: COEFFICIENT INTERPRETATION")
print("=" * 80)

print("""
  Logistic Regression Coefficient Interpretation:
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  â€¢ Positive coefficient â†’ feature INCREASES readmission probability
  â€¢ Negative coefficient â†’ feature DECREASES readmission probability
  â€¢ Odds Ratio = e^(coefficient)
    OR > 1 â†’ increases odds of readmission
    OR < 1 â†’ decreases odds of readmission
""")

coef_df = pd.DataFrame({
    'Feature': feature_cols,
    'Coefficient': best_model.coef_[0],
    'OddsRatio': np.exp(best_model.coef_[0])
}).sort_values('Coefficient', ascending=False)

print("--- Feature Coefficients (Sorted by Impact) ---")
print(f"\n{'Feature':<35} {'Coefficient':>12} {'Odds Ratio':>12} {'Direction':>12}")
print("-" * 75)
for _, row in coef_df.iterrows():
    direction = "â†‘ Risk" if row['Coefficient'] > 0 else "â†“ Risk"
    print(f"{row['Feature']:<35} {row['Coefficient']:>12.4f} {row['OddsRatio']:>12.4f} {direction:>12}")

print(f"\n--- Top 5 Risk-INCREASING Features ---")
for _, row in coef_df.head(5).iterrows():
    print(f"  {row['Feature']}: OR = {row['OddsRatio']:.3f} "
          f"(each unit increase â†’ {(row['OddsRatio'] - 1) * 100:.1f}% change in odds)")

print(f"\n--- Top 5 Risk-DECREASING Features ---")
for _, row in coef_df.tail(5).iterrows():
    print(f"  {row['Feature']}: OR = {row['OddsRatio']:.3f} "
          f"(each unit increase â†’ {(row['OddsRatio'] - 1) * 100:.1f}% change in odds)")

# ============================================================================
# STEP 10: SAMPLE PREDICTIONS WITH RISK TIERS
# ============================================================================
print("\n" + "=" * 80)
print("STEP 10: SAMPLE PATIENT PREDICTIONS WITH RISK TIERS")
print("=" * 80)

print("\n--- Patient Risk Stratification ---")
print(f"  HIGH RISK:   P â‰¥ 0.60 â†’ Immediate care coordinator intervention")
print(f"  MEDIUM RISK: P 0.40â€“0.59 â†’ Follow-up call within 48 hours")
print(f"  LOW RISK:    P < 0.40 â†’ Standard discharge instructions")

print(f"\n{'Patient':<10} {'Actual':>10} {'P(Readmit)':>12} {'Risk Tier':>15} {'Correct?':>10}")
print("-" * 60)

for i in range(20):
    actual = y_test.iloc[i]
    prob = y_prob[i]
    tier = "HIGH" if prob >= 0.6 else ("MEDIUM" if prob >= 0.4 else "LOW")
    predicted = 1 if prob >= best_thresh else 0
    correct = "âœ“" if predicted == actual else "âœ—"

    print(f"Patient {i + 1:<3} {actual:>10} {prob:>11.3f} {tier:>15} {correct:>10}")

# ============================================================================
# STEP 11: VISUALIZATIONS
# ============================================================================
print("\n" + "=" * 80)
print("STEP 11: CREATE COMPREHENSIVE VISUALIZATIONS")
print("=" * 80)

# --- Viz 1: Target Distribution ---
print("\nðŸ“Š Creating target distribution plot...")
fig, axes = plt.subplots(1, 3, figsize=(16, 5))

labels = ['Not Readmitted', 'Readmitted']
counts = [not_readmit_count, readmit_count]
colors = ['#2196F3', '#F44336']

axes[0].bar(labels, counts, color=colors, edgecolor='black', alpha=0.8)
axes[0].set_title('Readmission Class Distribution', fontsize=13, fontweight='bold')
axes[0].set_ylabel('Number of Patients', fontsize=11, fontweight='bold')
for i, (bar, count) in enumerate(zip(axes[0].patches, counts)):
    axes[0].text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 10,
                 f'{count}\n({count / n_patients * 100:.1f}%)',
                 ha='center', fontsize=11, fontweight='bold')

readmit_by_discharge = df.groupby('DischargeType')['Readmitted_30days'].mean().sort_values()
axes[1].barh(readmit_by_discharge.index, readmit_by_discharge.values,
             color='#FF9800', edgecolor='black', alpha=0.8)
axes[1].set_xlabel('Readmission Rate', fontsize=11, fontweight='bold')
axes[1].set_title('Readmission Rate by Discharge Type', fontsize=13, fontweight='bold')
axes[1].set_xlim(0, 0.6)
for i, v in enumerate(readmit_by_discharge.values):
    axes[1].text(v + 0.005, i, f'{v:.3f}', va='center', fontweight='bold')

readmit_by_diag = df.groupby('DiagnosisCategory')['Readmitted_30days'].mean().sort_values()
axes[2].barh(readmit_by_diag.index, readmit_by_diag.values,
             color='#9C27B0', edgecolor='black', alpha=0.8)
axes[2].set_xlabel('Readmission Rate', fontsize=11, fontweight='bold')
axes[2].set_title('Readmission Rate by Diagnosis', fontsize=13, fontweight='bold')
axes[2].set_xlim(0, 0.6)
for i, v in enumerate(readmit_by_diag.values):
    axes[2].text(v + 0.005, i, f'{v:.3f}', va='center', fontweight='bold')

plt.tight_layout()
plt.savefig('lr_viz_1_distribution.png', dpi=150, bbox_inches='tight')
plt.close()
print("  âœ“ Saved: lr_viz_1_distribution.png")

# --- Viz 2: ROC & PR Curves ---
print("\nðŸ“Š Creating ROC and PR curves...")
fig, axes = plt.subplots(1, 2, figsize=(14, 6))

fpr, tpr, _ = roc_curve(y_test, y_prob)
auc_score = roc_auc_score(y_test, y_prob)
axes[0].plot(fpr, tpr, color='#E91E63', lw=2.5,
             label=f'Logistic Regression (AUC = {auc_score:.4f})')
axes[0].plot([0, 1], [0, 1], 'k--', lw=1.5, label='Random Classifier (AUC = 0.50)')
axes[0].fill_between(fpr, tpr, alpha=0.1, color='#E91E63')
axes[0].set_xlabel('False Positive Rate (1 - Specificity)', fontsize=12, fontweight='bold')
axes[0].set_ylabel('True Positive Rate (Sensitivity)', fontsize=12, fontweight='bold')
axes[0].set_title('ROC Curve', fontsize=13, fontweight='bold')
axes[0].legend(fontsize=10)
axes[0].grid(True, alpha=0.3)

precision_c, recall_c, _ = precision_recall_curve(y_test, y_prob)
ap_score = average_precision_score(y_test, y_prob)
axes[1].plot(recall_c, precision_c, color='#009688', lw=2.5,
             label=f'Logistic Regression (AP = {ap_score:.4f})')
axes[1].axhline(y=readmit_rate, color='k', linestyle='--', lw=1.5,
                label=f'Baseline (Prevalence = {readmit_rate:.3f})')
axes[1].fill_between(recall_c, precision_c, alpha=0.1, color='#009688')
axes[1].set_xlabel('Recall (Sensitivity)', fontsize=12, fontweight='bold')
axes[1].set_ylabel('Precision (PPV)', fontsize=12, fontweight='bold')
axes[1].set_title('Precision-Recall Curve', fontsize=13, fontweight='bold')
axes[1].legend(fontsize=10)
axes[1].grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('lr_viz_2_roc_pr.png', dpi=150, bbox_inches='tight')
plt.close()
print("  âœ“ Saved: lr_viz_2_roc_pr.png")

# --- Viz 3: Confusion Matrix ---
print("\nðŸ“Š Creating confusion matrix...")
fig, axes = plt.subplots(1, 2, figsize=(14, 6))

for ax, (threshold, title) in zip(axes, [(0.5, 'Default (0.5)'), (best_thresh, f'Optimal ({best_thresh})')]):
    y_p_t = (y_prob >= threshold).astype(int)
    cm_t = confusion_matrix(y_test, y_p_t)
    sns.heatmap(cm_t, annot=True, fmt='d', cmap='Blues', ax=ax,
                xticklabels=['Not Readmitted', 'Readmitted'],
                yticklabels=['Not Readmitted', 'Readmitted'],
                annot_kws={"size": 14, "weight": "bold"})
    ax.set_xlabel('Predicted', fontsize=12, fontweight='bold')
    ax.set_ylabel('Actual', fontsize=12, fontweight='bold')
    ax.set_title(f'Confusion Matrix â€” Threshold {title}', fontsize=12, fontweight='bold')

plt.tight_layout()
plt.savefig('lr_viz_3_confusion_matrix.png', dpi=150, bbox_inches='tight')
plt.close()
print("  âœ“ Saved: lr_viz_3_confusion_matrix.png")

# --- Viz 4: Coefficients (Feature Impact) ---
print("\nðŸ“Š Creating coefficient plot...")
fig, ax = plt.subplots(figsize=(12, 8))

coef_plot = coef_df.copy()
colors_coef = ['#F44336' if c > 0 else '#2196F3' for c in coef_plot['Coefficient']]
bars = ax.barh(coef_plot['Feature'], coef_plot['Coefficient'],
               color=colors_coef, edgecolor='black', alpha=0.8)
ax.axvline(x=0, color='black', linewidth=1.5)
ax.set_xlabel('Coefficient Value (Log-Odds)', fontsize=12, fontweight='bold')
ax.set_title('Logistic Regression Coefficients\nRed = Increases Risk | Blue = Decreases Risk',
             fontsize=13, fontweight='bold')
ax.grid(axis='x', alpha=0.3)

from matplotlib.patches import Patch

legend_elements = [Patch(facecolor='#F44336', label='Increases Readmission Risk'),
                   Patch(facecolor='#2196F3', label='Decreases Readmission Risk')]
ax.legend(handles=legend_elements, fontsize=10)

plt.tight_layout()
plt.savefig('lr_viz_4_coefficients.png', dpi=150, bbox_inches='tight')
plt.close()
print("  âœ“ Saved: lr_viz_4_coefficients.png")

# --- Viz 5: Threshold Optimization ---
print("\nðŸ“Š Creating threshold optimization plot...")
fig, axes = plt.subplots(1, 2, figsize=(14, 6))

axes[0].plot(thresh_df['Threshold'], thresh_df['Recall'], 'b-o', markersize=5, label='Recall (Sensitivity)')
axes[0].plot(thresh_df['Threshold'], thresh_df['Precision'], 'r-s', markersize=5, label='Precision')
axes[0].plot(thresh_df['Threshold'], thresh_df['F1'], 'g-^', markersize=5, label='F1-Score')
axes[0].axvline(x=best_thresh, color='orange', linestyle='--', lw=2, label=f'Optimal Threshold ({best_thresh})')
axes[0].set_xlabel('Decision Threshold', fontsize=12, fontweight='bold')
axes[0].set_ylabel('Score', fontsize=12, fontweight='bold')
axes[0].set_title('Threshold vs Performance Metrics', fontsize=13, fontweight='bold')
axes[0].legend(fontsize=10)
axes[0].grid(True, alpha=0.3)

# Probability distribution by class
y_prob_readmit = y_prob[y_test == 1]
y_prob_no_readmit = y_prob[y_test == 0]
axes[1].hist(y_prob_no_readmit, bins=30, alpha=0.6, color='#2196F3',
             label='Not Readmitted', edgecolor='black')
axes[1].hist(y_prob_readmit, bins=30, alpha=0.6, color='#F44336',
             label='Readmitted', edgecolor='black')
axes[1].axvline(x=0.5, color='black', linestyle='--', lw=2, label='Default (0.5)')
axes[1].axvline(x=best_thresh, color='orange', linestyle='--', lw=2, label=f'Optimal ({best_thresh})')
axes[1].set_xlabel('Predicted Probability of Readmission', fontsize=12, fontweight='bold')
axes[1].set_ylabel('Number of Patients', fontsize=12, fontweight='bold')
axes[1].set_title('Predicted Probability Distribution by Class', fontsize=13, fontweight='bold')
axes[1].legend(fontsize=10)
axes[1].grid(axis='y', alpha=0.3)

plt.tight_layout()
plt.savefig('lr_viz_5_threshold.png', dpi=150, bbox_inches='tight')
plt.close()
print("  âœ“ Saved: lr_viz_5_threshold.png")

# --- Viz 6: Regularization Comparison ---
print("\nðŸ“Š Creating regularization comparison...")
reg_names = list(results.keys())
reg_auc = [results[k]['ROC-AUC'] for k in reg_names]
reg_f1 = [results[k]['F1-Score'] for k in reg_names]
reg_acc = [results[k]['Accuracy'] for k in reg_names]

x_pos = np.arange(len(reg_names))
width = 0.25

fig, ax = plt.subplots(figsize=(12, 6))
ax.bar(x_pos - width, reg_acc, width, label='Accuracy', color='#3F51B5', edgecolor='black', alpha=0.8)
ax.bar(x_pos, reg_auc, width, label='ROC-AUC', color='#E91E63', edgecolor='black', alpha=0.8)
ax.bar(x_pos + width, reg_f1, width, label='F1-Score', color='#4CAF50', edgecolor='black', alpha=0.8)
ax.set_xticks(x_pos)
ax.set_xticklabels(reg_names, fontsize=10)
ax.set_ylabel('Score', fontsize=12, fontweight='bold')
ax.set_title('Regularization Strength Comparison', fontsize=13, fontweight='bold')
ax.set_ylim(0, 1.1)
ax.legend(fontsize=11)
ax.grid(axis='y', alpha=0.3)

plt.tight_layout()
plt.savefig('lr_viz_6_regularization.png', dpi=150, bbox_inches='tight')
plt.close()
print("  âœ“ Saved: lr_viz_6_regularization.png")

# --- Viz 7: Risk Tier Distribution ---
print("\nðŸ“Š Creating risk tier plot...")
risk_tiers = pd.cut(y_prob,
                    bins=[-0.001, 0.4, 0.6, 1.001],
                    labels=['LOW RISK\n(<0.40)', 'MEDIUM RISK\n(0.40â€“0.60)', 'HIGH RISK\n(>0.60)'])
tier_df = pd.DataFrame({'Tier': risk_tiers, 'Actual': y_test.values})
tier_counts = tier_df['Tier'].value_counts().sort_index()

fig, axes = plt.subplots(1, 2, figsize=(14, 6))

tier_colors = ['#4CAF50', '#FF9800', '#F44336']
axes[0].bar(tier_counts.index, tier_counts.values,
            color=tier_colors, edgecolor='black', alpha=0.8)
axes[0].set_title('Patient Risk Tier Distribution', fontsize=13, fontweight='bold')
axes[0].set_ylabel('Number of Patients', fontsize=11, fontweight='bold')
for bar, count in zip(axes[0].patches, tier_counts.values):
    axes[0].text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 2,
                 f'{count}\n({count / len(y_test) * 100:.1f}%)',
                 ha='center', fontsize=11, fontweight='bold')

actual_readmit_by_tier = tier_df.groupby('Tier')['Actual'].mean()
axes[1].bar(actual_readmit_by_tier.index, actual_readmit_by_tier.values,
            color=tier_colors, edgecolor='black', alpha=0.8)
axes[1].set_title('Actual Readmission Rate by Risk Tier', fontsize=13, fontweight='bold')
axes[1].set_ylabel('Actual Readmission Rate', fontsize=11, fontweight='bold')
axes[1].set_ylim(0, 0.8)
for bar, v in zip(axes[1].patches, actual_readmit_by_tier.values):
    axes[1].text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.01,
                 f'{v:.3f}', ha='center', fontsize=12, fontweight='bold')
axes[1].axhline(y=readmit_rate, color='black', linestyle='--', lw=1.5, label=f'Overall Rate ({readmit_rate:.3f})')
axes[1].legend(fontsize=10)

plt.suptitle('Patient Risk Stratification System', fontsize=14, fontweight='bold')
plt.tight_layout()
plt.savefig('lr_viz_7_risk_tiers.png', dpi=150, bbox_inches='tight')
plt.close()
print("  âœ“ Saved: lr_viz_7_risk_tiers.png")

# ============================================================================
# STEP 12: COMPREHENSIVE REPORT
# ============================================================================
print("\n" + "=" * 80)
print("STEP 12: GENERATE COMPREHENSIVE REPORT")
print("=" * 80)

report = f"""
{'=' * 80}
LOGISTIC REGRESSION CLASSIFICATION - HOSPITAL READMISSION PREDICTION
{'=' * 80}

BUSINESS OBJECTIVE
{'=' * 80}
Predict which patients will be readmitted to the hospital within 30 days
of discharge, to enable targeted interventions that improve outcomes and
reduce CMS (Centers for Medicare & Medicaid) readmission penalties.

WHY LOGISTIC REGRESSION FOR HEALTHCARE?
  â€¢ Outputs probabilities â†’ Risk stratification tiers
  â€¢ Interpretable coefficients â†’ Clinicians trust the model
  â€¢ FDA/regulatory compliance â†’ Explainable AI
  â€¢ Efficient training â†’ Fast enough for real-time scoring
  â€¢ Handles mixed data types well

DATASET SUMMARY
{'=' * 80}
Total patients:   {n_patients}
Features:         {len(feature_cols)}
Readmitted (30d): {readmit_count} ({readmit_rate * 100:.1f}%)
Not Readmitted:   {not_readmit_count} ({(1 - readmit_rate) * 100:.1f}%)

Feature Categories:
  Numerical  : Age, LengthOfStay, NumDiagnoses, NumProcedures,
               NumMedications, NumLabTests, NumPrevAdmissions,
               ComorbidityScore, DaysSinceLastAdm
  Categorical: HbA1c, DischargeType, DiagnosisCategory,
               InsuranceType, ERAdmission

PREPROCESSING
{'=' * 80}
  â€¢ Stratified train/test split (80/20)
  â€¢ StandardScaler on numerical features
  â€¢ Label encoding for ordinal categories
  â€¢ One-Hot encoding for nominal categories
  â€¢ No missing values generated

MODEL COMPARISON (REGULARIZATION SWEEP)
{'=' * 80}

{"Model":<30} {"Accuracy":>10} {"ROC-AUC":>10} {"F1-Score":>10} {"Avg Precision":>15}
{"-" * 75}
{chr(10).join([f"{k:<30} {v['Accuracy']:>10.4f} {v['ROC-AUC']:>10.4f} {v['F1-Score']:>10.4f} {v['Avg Precision']:>15.4f}"
               for k, v in results.items()])}

Best Model: {best_name}
  ROC-AUC = {results[best_name]['ROC-AUC']:.4f}

BEST MODEL PERFORMANCE
{'=' * 80}
Threshold: {best_thresh} (optimized for F1)

  Confusion Matrix:
    True Negatives  (Not Readmitted, Correct): {tn}
    False Positives (Predicted Readmit, Wrong): {fp}
    False Negatives (Missed Readmission!):      {fn}
    True Positives  (Caught Readmission):       {tp}

  Clinical Metrics:
    Sensitivity (Recall):  {sensitivity:.4f}  ({sensitivity * 100:.1f}% of readmissions caught)
    Specificity:           {specificity:.4f}  ({specificity * 100:.1f}% of non-readmits correct)
    Positive Pred Value:   {ppv:.4f}
    Negative Pred Value:   {npv:.4f}
    ROC-AUC:               {results[best_name]['ROC-AUC']:.4f}

CROSS-VALIDATION (5-Fold Stratified)
{'=' * 80}
  ROC-AUC: {cv_auc.mean():.4f} Â± {cv_auc.std():.4f}
  F1-Score: {cv_f1.mean():.4f} Â± {cv_f1.std():.4f}
  Stability: {"âœ“ Excellent" if cv_auc.std() < 0.02 else "âœ“ Good" if cv_auc.std() < 0.05 else "âš  Variable"}

TOP FEATURE IMPACT (COEFFICIENTS)
{'=' * 80}
{chr(10).join([f"  {row['Feature']:<35} Coef: {row['Coefficient']:>8.4f}  OR: {row['OddsRatio']:>8.4f}"
               for _, row in coef_df.iterrows()])}

RISK STRATIFICATION TIERS
{'=' * 80}
  HIGH RISK   (P > 0.60): {(y_prob > 0.6).sum()} patients  â†’ Care coordinator intervention
  MEDIUM RISK (P 0.4-0.6): {((y_prob >= 0.4) & (y_prob <= 0.6)).sum()} patients â†’ 48hr follow-up call
  LOW RISK    (P < 0.40): {(y_prob < 0.4).sum()} patients  â†’ Standard discharge

CLINICAL INSIGHTS
{'=' * 80}
  â€¢ Top risk-increasing factors: {', '.join(coef_df.head(3)['Feature'].tolist())}
  â€¢ Top protective factors: {', '.join(coef_df.tail(3)['Feature'].tolist())}
  â€¢ AMA discharge dramatically increases readmission odds
  â€¢ Each additional prior admission increases readmission risk
  â€¢ Recent admissions (short days-since-last) â†’ higher risk

BUSINESS RECOMMENDATIONS
{'=' * 80}
  1. Implement risk scoring at discharge for all patients
  2. Focus interventions on HIGH RISK patients (>P{best_thresh})
  3. Prioritize AMA discharge patients for outreach
  4. Address social determinants (Self-Pay â†’ care access)
  5. Diabetic patients with abnormal HbA1c need enhanced follow-up
  6. Reduce medication complexity (polypharmacy â†’ higher risk)

FILES GENERATED
{'=' * 80}
  â€¢ hospital_readmission_data.csv
  â€¢ lr_viz_1_distribution.png
  â€¢ lr_viz_2_roc_pr.png
  â€¢ lr_viz_3_confusion_matrix.png
  â€¢ lr_viz_4_coefficients.png
  â€¢ lr_viz_5_threshold.png
  â€¢ lr_viz_6_regularization.png
  â€¢ lr_viz_7_risk_tiers.png

{'=' * 80}
END OF REPORT
{'=' * 80}
"""

print(report)
with open('lr_analysis_report.txt', 'w', encoding='utf-8') as f:
    f.write(report)
print("\nâœ“ Report saved to: lr_analysis_report.txt")

# ============================================================================
# FINAL SUMMARY
# ============================================================================
print("\n" + "=" * 80)
print("LOGISTIC REGRESSION CLASSIFICATION COMPLETE!")
print("=" * 80)
print(f"\nðŸ“Š Summary:")
print(f"  âœ“ Generated {n_patients} patient discharge records")
print(f"  âœ“ Readmission rate: {readmit_rate * 100:.1f}%")
print(f"  âœ“ Best model: {best_name}")
print(f"  âœ“ ROC-AUC: {results[best_name]['ROC-AUC']:.4f}")
print(f"  âœ“ Sensitivity: {sensitivity * 100:.1f}% of readmissions caught")
print(f"  âœ“ Optimal threshold: {best_thresh}")
print(f"  âœ“ Generated 7 comprehensive visualizations")
print(f"\nðŸ’¡ Key Findings:")
print(f"  â€¢ Model discriminates readmitted vs non-readmitted (AUC = {results[best_name]['ROC-AUC']:.4f})")
print(f"  â€¢ {(y_prob > 0.6).sum()} HIGH RISK patients identified for immediate intervention")
print(f"  â€¢ AMA discharge is the strongest readmission risk factor")
print(f"  â€¢ Previous admissions and comorbidity score are top clinical predictors")
print("\n" + "=" * 80)
print("All analysis complete! Check output files for detailed results.")
print("=" * 80)