
================================================================================
USER COURSE REVIEWS - COMPLETE ANALYSIS REPORT
================================================================================

DATASET SUMMARY
================================================================================
Original file: user_courses_review_09_2023.csv
Processed file: reviews_preprocessed.csv

Total records: 10840
Records after cleaning: 10635
Records removed: 205

Columns: ['course_name', 'lecture_name', 'review_rating', 'review_comment']

PREPROCESSING STEPS
================================================================================
1. ✓ Data Loading - Loaded 10840 reviews
2. ✓ Missing Value Handling - Removed 205 rows
3. ✓ Text Cleaning - Lowercase, strip whitespace
4. ✓ Feature Engineering - Added comment_length, word_count
5. ✓ Text Vectorization - TF-IDF with 1000 features

EXPLORATORY DATA ANALYSIS
================================================================================
Rating Distribution:
review_rating
1      47
2      75
3     245
4     765
5    9503

Comment Statistics:
  Average length: 45.36 characters
  Average words: 7.74 words
  Median length: 20.00 characters

Top 3 Courses:
  1. Introduction to Data and Data Science: 1706 reviews
  2. Introduction to Excel: 1066 reviews
  3. Intro to ChatGPT and Generative AI: 739 reviews

Correlations:
  Rating vs Comment Length: -0.2885
  Rating vs Word Count: -0.2906

NAIVE BAYES CLASSIFICATION
================================================================================
Task: Binary classification (Good vs Bad reviews)
  - Bad (1-3 stars): 367 reviews
  - Good (4-5 stars): 10268 reviews

Algorithm: Multinomial Naive Bayes
Features: TF-IDF vectorization (1000 features)
Training samples: 8508
Test samples: 2127

MODEL PERFORMANCE
================================================================================
Overall Accuracy: 0.9676 (96.76%)

Per-Class Metrics:
  Bad Reviews (1-3):
    Precision: 0.7000
    Recall: 0.0959
    F1-Score: 0.1687

  Good Reviews (4-5):
    Precision: 0.9688
    Recall: 0.9985
    F1-Score: 0.9835

Weighted Averages:
  Precision: 0.9596
  Recall: 0.9676
  F1-Score: 0.9555

Confusion Matrix:
                Predicted Bad  Predicted Good
  Actual Bad           7             66  
  Actual Good          3            2051 

KEY INSIGHTS
================================================================================
• 96.5% of reviews are positive (4-5 stars)
• Model achieves 96.8% accuracy in predicting review sentiment
• Average prediction confidence: 0.973
• TF-IDF effectively captures review sentiment from text
• Multinomial Naive Bayes performs well on text classification

TOP PREDICTIVE WORDS
================================================================================
Words indicating Bad reviews:
  1. good
  2. course
  3. need
  4. video
  5. like
  6. content
  7. practice
  8. just
  9. examples
  10. better

Words indicating Good reviews:
  1. excellent
  2. good
  3. great
  4. course
  5. amazing
  6. nice
  7. awesome
  8. informative
  9. easy
  10. really

FILES GENERATED
================================================================================
Data Files:
  • reviews_preprocessed.csv - Cleaned and preprocessed data

EDA Visualizations:
  • eda_viz_1_rating_distribution.png
  • eda_viz_2_top_courses.png
  • eda_viz_3_comment_length.png
  • eda_viz_4_rating_vs_length.png
  • eda_viz_5_correlation_heatmap.png
  • eda_viz_6_wordcount_by_rating.png

Model Evaluation:
  • eval_viz_1_confusion_matrix.png
  • eval_viz_2_metrics.png
  • eval_viz_3_confidence.png
  • eval_viz_4_feature_importance.png

================================================================================
END OF REPORT
================================================================================
